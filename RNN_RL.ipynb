{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* colors: Number of colors\n",
    "\n",
    "* C: number of classes\n",
    "\n",
    "* A: actions {l:left, r:right, a:above, b:below}\n",
    "\n",
    "* cube: adjacency matrix of the cube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenges\n",
    "* What and when to give rewards?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things that can go wrong:\n",
    "* Stop gradient in the mean_actions\n",
    "* Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the cube adjancy matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cube = np.array([[1, 3, 4, 5], [2,0,4,5], [3,1,4,5], [0,2,4,5], [1,3,2,0], [3,1,2,0]], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* generate a dataset\n",
    "* Assume that we are generating 10 classes, with 10 colors in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "num_actions = 4\n",
    "hid_dim = 10\n",
    "gamma = 1\n",
    "num_colors = 10\n",
    "num_classes = batch_size\n",
    "num_faces = 6\n",
    "SMALL_NUM = 1e-10\n",
    "initLr = 0.1\n",
    "lrDecayRate = .995\n",
    "lrDecayFreq = 500\n",
    "momentumValue = .9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]], dtype=int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.random.randint(num_colors, size=(batch_size, num_faces))\n",
    "y = np.arange(num_classes)\n",
    "# converting in one-hot representation\n",
    "X_train = np.zeros((batch_size, num_faces, num_colors))\n",
    "for i in range(batch_size):\n",
    "    for j in range(num_faces):\n",
    "        X_train[i, j, X[i, j]] = 1\n",
    "\n",
    "# Make the y one-hot representation\n",
    "y_train = np.zeros((batch_size, num_classes))\n",
    "for i in range(batch_size):\n",
    "    y_train[i, y[i]] = 1\n",
    "X_train.astype(np.int32)\n",
    "y_train.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 6, 8, 8, 0, 9],\n",
       "       [7, 7, 7, 4, 6, 7],\n",
       "       [9, 9, 0, 8, 5, 1],\n",
       "       [2, 9, 6, 0, 1, 3],\n",
       "       [2, 7, 7, 0, 0, 8],\n",
       "       [7, 1, 9, 8, 9, 1],\n",
       "       [7, 8, 5, 3, 6, 8],\n",
       "       [4, 6, 2, 7, 7, 0],\n",
       "       [5, 4, 8, 5, 3, 3],\n",
       "       [1, 7, 4, 4, 8, 0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Define the computation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_kernel(kernel_shape, bias_shape):\n",
    "    # Create variable named \"weights\".\n",
    "    weights = tf.get_variable(\"weights\", kernel_shape,\n",
    "        initializer=tf.random_normal_initializer())\n",
    "    # Create variable named \"biases\".\n",
    "    biases = tf.get_variable(\"biases\", bias_shape,\n",
    "                             initializer=tf.random_normal_initializer())\n",
    "    return weights, biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_next_batch(x, init_view, actions, cube):\n",
    "    \"\"\" Get the slice of the next input from the placeholder x\n",
    "    given the next location (left, right, above, below) to look at.\n",
    "    One thing to make sure that you need to first sample to face index\n",
    "    from the cube adjagit remote add origin git@github.com:GodOfProbability/RL-for-shape.gitcency matrix, given the current face and the action\n",
    "    taken.Init_views[901]\n",
    "    : param x: complete data matrix, of shape: (batch_size, num_faces, num_colors)\n",
    "    : param init_view: the current face indices in the batch_x\n",
    "    : param actions: the action taken (l, r, a, b)\n",
    "    : param cube: the cube data adjacency matrix.\n",
    "    : return batch_x: the next_batch \n",
    "    \"\"\"\n",
    "#     init_view = tf.argmax(init_view, 1)\n",
    "    init_view = tf.cast(init_view, dtype=tf.int32)\n",
    "    size = [1, num_colors]\n",
    "    batch_x = []\n",
    "    face_indices = []\n",
    "    for i in range(batch_size):\n",
    "        # from actions, find the face index\n",
    "        face_index = cube[init_view[i, 0], actions[i, 0]]\n",
    "        face_indices.append(face_index)\n",
    "        begin = [face_index, 0]\n",
    "        z = tf.slice(x[i, :, :], begin=begin, size=size, name=\"z_slicing\")\n",
    "        z = tf.reshape(z, shape=[tf.shape(z)[-1]])\n",
    "        batch_x.append(z)\n",
    "    batch_x = tf.pack(batch_x, axis=0)\n",
    "    face_indices = tf.pack(face_indices, axis=0)\n",
    "    face_indices = tf.reshape(face_indices, shape = [tf.shape(face_indices)[0], 1])\n",
    "    return batch_x, face_indices\n",
    "\n",
    "def get_init_view(x, init_view):\n",
    "    \"\"\"Given the complete data matrix, give me the batch_x\n",
    "    :param x: complete data matrix, of shape: (batch_size, num_faces, num_colors)\n",
    "    :param init_view: the indices of the faces of the cube that \n",
    "    you see on the first time\n",
    "    :return batch_x: the batch for learning of shape (batch_size x num_colors)\n",
    "    the colors are represented in one-hot way.\n",
    "    \"\"\"\n",
    "\n",
    "    size = [1, num_colors]\n",
    "    batch_x = []\n",
    "    for i in range(batch_size):\n",
    "        begin = [init_view[i, 0], 0]\n",
    "        z = tf.slice(x[i, :, :], begin=begin, size=size)\n",
    "        z = tf.reshape(z, shape=[tf.shape(z)[-1]], name=\"z_slicing\")\n",
    "        batch_x.append(z)\n",
    "    batch_x = tf.pack(batch_x, axis=0)\n",
    "    return batch_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# x = tf.constant(X_train)\n",
    "# cubes = tf.constant(cube)\n",
    "# initial_view = tf.constant(y_train[:, 0].reshape((10, 1)))\n",
    "# actions = tf.constant([[1], [2], [3], [0], [1], [2], [3], [0], [2], [1]], dtype=tf.int32)\n",
    "# batch_x, face_indices = get_next_batch(x, initial_view, actions, cubes)\n",
    "# with tf.Session() as sess:\n",
    "#     print (sess.run(face_indices).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def model(cube):\n",
    "    x = tf.placeholder(name=\"input_data\", shape=[None, num_faces, num_colors], dtype=tf.float32) # total number of colors are 10 in one hot way\n",
    "    y = tf.placeholder(name=\"labels\", shape=[None, num_classes], dtype=tf.float32)\n",
    "    cube = tf.constant(cube)\n",
    "    REUSE = False\n",
    "    COSTS = []\n",
    "    Rewards = []\n",
    "    accuracies = []\n",
    "    initial_views = []\n",
    "    # randomly generate first input view location.\n",
    "    init_view = tf.random_uniform((batch_size, 1), minval=0, maxval=num_faces)\n",
    "    init_view = tf.to_int32(init_view, name='ToInt32')\n",
    "    hidden = tf.truncated_normal(shape=[batch_size, hid_dim], mean=0.0, stddev=0.1, dtype=tf.float32, seed=None, name=None)\n",
    "    with tf.name_scope(\"init_view\") as scope:\n",
    "        batch_x = get_init_view(x, init_view)\n",
    "    for i in range(6):\n",
    "        print (i)\n",
    "        initial_views.append(init_view)\n",
    "        with tf.variable_scope(\"x_hidden\", reuse=REUSE):\n",
    "            W_x, _ = get_kernel(kernel_shape=[num_colors, hid_dim], bias_shape=[hid_dim])\n",
    "\n",
    "        with tf.variable_scope(\"hidden_hidden\", reuse=REUSE):\n",
    "            W_h, b_h = get_kernel(kernel_shape=[hid_dim, hid_dim], bias_shape=[hid_dim])\n",
    "\n",
    "        with tf.variable_scope(\"class\", reuse=REUSE):\n",
    "            W_c, b_c = get_kernel(kernel_shape=[hid_dim, num_classes], bias_shape=[num_classes])\n",
    "\n",
    "        with tf.variable_scope(\"action\", reuse=REUSE):\n",
    "            W_a, b_a = get_kernel(kernel_shape=[hid_dim, num_actions], bias_shape=[num_actions])\n",
    "\n",
    "        with tf.name_scope(\"x_to_hid\") as scope:\n",
    "            # Construct a linear model\n",
    "            x_hidden = tf.matmul(batch_x, W_x)\n",
    "        with tf.name_scope(\"hid_to_hid\") as scope:\n",
    "            h_hid = tf.matmul(hidden, W_h) + b_h\n",
    "            \n",
    "        with tf.name_scope(\"hidden_t\") as scope:\n",
    "            hidden = tf.sigmoid(x_hidden + h_hid)\n",
    "\n",
    "        with tf.name_scope(\"classification\") as scope:\n",
    "            probs = tf.nn.softmax(tf.matmul(hidden, W_c) + b_c)  # Softmax prob for classes\n",
    "        \n",
    "        mean_actions = tf.nn.softmax(tf.matmul(hidden, W_a) + b_a)  # Softmax prob for actions\n",
    "        \n",
    "        # sample from these actions\n",
    "        samp_action = tf.multinomial(mean_actions, 1,)\n",
    "        samp_action = tf.cast(samp_action, dtype=tf.int32)\n",
    "        tf.stop_gradient(samp_action) # Stop the gradient flowing from non-differential cube-view sampling\n",
    "        \n",
    "        # define the rewards\n",
    "        max_p_y = tf.arg_max(probs, 1)\n",
    "        max_y = tf.arg_max(y, 1)\n",
    "\n",
    "        equals = tf.equal(max_p_y,max_y)\n",
    "        equals = tf.cast(equals, tf.float32)\n",
    "        acc = tf.reduce_mean(equals)\n",
    "        \n",
    "        R = equals\n",
    "        R = tf.reshape(R, (batch_size, 1))\n",
    "        \n",
    "        # Loss function corresponding to the policy\n",
    "        # I guess this is the probility of the action getting selected under softmax assumption\n",
    "        with tf.name_scope(\"policy_gradient\") as scope:\n",
    "#             p_loc = tf].zeros_like(samp_action, dtype=tf.float32)\n",
    "            p_loc = []\n",
    "            for index in range(batch_size):\n",
    "                p_loc.append(mean_actions[index, samp_action[index, 0]])\n",
    "            p_loc = tf.pack(p_loc, axis=0)\n",
    "            loss_p = tf.log(p_loc) * (R) * (gamma**i)\n",
    "        # Loss function correponding to the class prediction\n",
    "        with tf.name_scope(\"class_loss\") as scope:\n",
    "            # Minimize error using cross entropy, y is in one-hot representation\n",
    "            loss_class = y * tf.log(probs)\n",
    "            \n",
    "        J = tf.concat(1, [loss_p, loss_class])\n",
    "        J = tf.reduce_sum(J, 1)\n",
    "        J = tf.reduce_mean(J, 0)\n",
    "\n",
    "        cost = -J\n",
    "        COSTS.append(cost)\n",
    "        accuracies.append(acc)\n",
    "        Rewards.append(R)\n",
    "\n",
    "        with tf.name_scope(\"get_next_batch\") as scope:\n",
    "            batch_x, init_view = get_next_batch(x, init_view, samp_action, cube)\n",
    "\n",
    "        # Don't use the initialized variable again\n",
    "        REUSE = True\n",
    "    COSTS = tf.reduce_sum(COSTS)\n",
    "    reward = tf.reduce_mean(Rewards)\n",
    "#     accuracy = tf.reduce_mean(accuracies)\n",
    "    with tf.name_scope(\"train\") as scope:\n",
    "        # Gradient descent\n",
    "        optimizer = tf.train.GradientDescentOptimizer(lr).minimize(COSTS)\n",
    "    return x, y, COSTS, Rewards, accuracies, optimizer, initial_views, equals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "global_step = tf.Variable(0, trainable=False, dtype=tf.int32)\n",
    "lr = tf.train.exponential_decay(initLr, global_step, lrDecayFreq, lrDecayRate, staircase=True, )\n",
    "x, y, costs, reward, acc, optimizer, initital_views, equals = model(cube)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define few baseline experiments:\n",
    "* The cube is not rotated and their is a fixed policy\n",
    "* The cube is rotated and their is a fixed policy.\n",
    "* The cube is not rotated and their is a random policy.\n",
    "* The cube is rotated and their is a random policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    accuracies = []\n",
    "    rewards = []\n",
    "    Init_views = []\n",
    "    COSTS = []\n",
    "    for i in range(1000):\n",
    "#         print (i)\n",
    "        l = np.arange(batch_size)\n",
    "        np.random.shuffle(l)\n",
    "        X_train = X_train[l]\n",
    "        y_train = y_train[l]\n",
    "        acc_, reward_, _ = sess.run([acc, reward, optimizer], feed_dict={x:X_train, y:y_train})\n",
    "        accuracies.append(acc_)\n",
    "        rewards.append(reward_)\n",
    "#         Init_views.append(initial_views)\n",
    "#         COSTS.append(costs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.30000001, 0.60000002, 0.60000002, 0.89999998, 0.89999998, 0.70000005],\n",
       " [0.30000001, 0.80000001, 0.80000001, 0.89999998, 0.89999998, 0.89999998],\n",
       " [0.30000001, 0.60000002, 0.30000001, 0.5, 0.40000001, 0.60000002],\n",
       " [0.40000001, 0.30000001, 0.5, 0.5, 0.60000002, 0.60000002],\n",
       " [0.1, 0.2, 0.5, 0.80000001, 0.80000001, 0.70000005],\n",
       " [0.5, 0.5, 0.80000001, 0.89999998, 0.80000001, 0.89999998],\n",
       " [0.30000001, 0.60000002, 0.80000001, 0.60000002, 0.60000002, 0.70000005],\n",
       " [0.2, 0.40000001, 0.60000002, 0.80000001, 0.80000001, 0.70000005],\n",
       " [0.30000001, 0.70000005, 0.89999998, 0.70000005, 0.80000001, 0.80000001],\n",
       " [0.30000001, 0.5, 0.60000002, 0.80000001, 0.89999998, 0.89999998],\n",
       " [0.2, 0.40000001, 0.70000005, 0.80000001, 0.80000001, 0.70000005],\n",
       " [0.2, 0.60000002, 0.60000002, 0.70000005, 0.5, 0.60000002],\n",
       " [0.5, 0.30000001, 0.60000002, 0.5, 0.89999998, 0.70000005],\n",
       " [0.2, 0.69999999, 0.80000001, 0.70000005, 0.70000005, 0.60000002],\n",
       " [0.2, 0.60000002, 0.40000001, 0.70000005, 0.70000005, 0.60000002],\n",
       " [0.60000002, 0.70000005, 0.69999999, 0.80000001, 0.70000005, 0.80000001],\n",
       " [0.1, 0.5, 0.5, 0.89999998, 0.70000005, 0.89999998],\n",
       " [0.1, 0.70000005, 0.60000002, 0.60000002, 0.70000005, 0.70000005],\n",
       " [0.40000001, 0.5, 0.70000005, 0.70000005, 0.60000002, 0.70000005],\n",
       " [0.1, 0.30000001, 0.5, 0.70000005, 0.70000005, 0.80000001],\n",
       " [0.40000001, 0.5, 0.70000005, 0.89999998, 0.80000001, 0.80000001],\n",
       " [0.2, 0.70000005, 0.70000005, 0.70000005, 0.80000001, 0.80000001],\n",
       " [0.30000001, 0.60000002, 0.80000001, 0.69999999, 0.80000001, 0.70000005],\n",
       " [0.2, 0.30000001, 0.40000001, 0.60000002, 0.60000002, 0.80000001],\n",
       " [0.1, 0.30000001, 0.5, 0.60000002, 0.70000005, 0.89999998],\n",
       " [0.40000001, 0.5, 0.5, 0.89999998, 0.80000001, 0.80000001],\n",
       " [0.40000001, 0.40000001, 0.60000002, 0.80000001, 0.60000002, 0.80000001],\n",
       " [0.30000001, 0.40000001, 0.60000002, 0.80000001, 0.89999998, 0.80000001],\n",
       " [0.2, 0.2, 0.70000005, 0.80000001, 0.5, 0.80000001],\n",
       " [0.30000001, 0.60000002, 0.5, 0.60000002, 0.80000001, 0.80000001],\n",
       " [0.60000002, 0.60000002, 0.70000005, 0.80000001, 0.89999998, 0.80000001],\n",
       " [0.0, 0.30000001, 0.30000001, 0.5, 0.60000002, 0.69999999],\n",
       " [0.30000001, 0.40000001, 0.89999998, 0.89999998, 0.89999998, 0.89999998],\n",
       " [0.2, 0.30000001, 0.70000005, 0.5, 0.89999998, 0.69999999],\n",
       " [0.30000001, 0.60000002, 0.5, 0.80000001, 0.60000002, 0.80000001],\n",
       " [0.40000001, 0.40000001, 0.60000002, 0.80000001, 0.80000001, 0.60000002],\n",
       " [0.2, 0.40000001, 0.5, 0.40000001, 0.60000002, 0.70000005],\n",
       " [0.2, 0.70000005, 0.80000001, 0.60000002, 0.89999998, 0.70000005],\n",
       " [0.2, 0.70000005, 0.60000002, 0.60000002, 0.70000005, 0.60000002],\n",
       " [0.2, 0.30000001, 0.80000001, 0.5, 0.80000001, 0.80000001],\n",
       " [0.69999999, 0.80000001, 1.0, 0.70000005, 0.80000001, 0.60000002],\n",
       " [0.2, 0.5, 0.5, 0.80000001, 0.60000002, 0.60000002],\n",
       " [0.40000001, 0.30000001, 0.5, 0.80000001, 0.80000001, 0.70000005],\n",
       " [0.1, 0.5, 0.70000005, 0.70000005, 0.89999998, 0.89999998],\n",
       " [0.30000001, 0.5, 0.70000005, 0.60000002, 0.70000005, 0.80000001],\n",
       " [0.30000001, 0.60000002, 0.89999998, 0.89999998, 0.80000001, 0.89999998],\n",
       " [0.2, 0.60000002, 0.70000005, 0.89999998, 0.80000001, 0.80000001],\n",
       " [0.30000001, 0.60000002, 0.60000002, 0.80000001, 0.89999998, 0.89999998],\n",
       " [0.69999999, 0.60000002, 0.70000005, 0.60000002, 0.80000001, 0.70000005],\n",
       " [0.2, 0.40000001, 0.60000002, 0.60000002, 0.70000005, 0.5],\n",
       " [0.40000001, 0.5, 0.60000002, 0.80000001, 0.80000001, 1.0],\n",
       " [0.30000001, 0.60000002, 0.89999998, 0.80000001, 0.70000005, 0.80000001],\n",
       " [0.2, 0.5, 0.60000002, 0.70000005, 0.80000001, 0.80000001],\n",
       " [0.40000001, 0.60000002, 0.70000005, 0.80000001, 0.80000001, 0.70000005],\n",
       " [0.30000001, 0.80000001, 0.70000005, 0.80000001, 0.70000005, 0.70000005],\n",
       " [0.30000001, 0.40000001, 0.70000005, 0.70000005, 0.80000001, 0.80000001],\n",
       " [0.40000001, 0.60000002, 0.80000001, 1.0, 0.80000001, 0.89999998],\n",
       " [0.30000001, 0.40000001, 0.60000002, 0.70000005, 0.70000005, 0.60000002],\n",
       " [0.5, 0.5, 0.60000002, 0.69999999, 0.69999999, 0.70000005],\n",
       " [0.30000001, 0.30000001, 0.60000002, 0.80000001, 0.80000001, 0.69999999],\n",
       " [0.40000001, 0.5, 0.80000001, 0.89999998, 0.70000005, 0.80000001],\n",
       " [0.2, 0.40000001, 0.60000002, 0.70000005, 0.89999998, 0.80000001],\n",
       " [0.2, 0.60000002, 0.80000001, 0.60000002, 0.89999998, 0.60000002],\n",
       " [0.2, 0.30000001, 0.60000002, 0.80000001, 0.69999999, 0.70000005],\n",
       " [0.30000001, 0.69999999, 0.70000005, 0.89999998, 0.89999998, 0.80000001],\n",
       " [0.2, 0.60000002, 0.5, 0.70000005, 0.80000001, 0.89999998],\n",
       " [0.2, 0.5, 0.70000005, 0.70000005, 0.70000005, 0.69999999],\n",
       " [0.2, 0.5, 0.40000001, 0.89999998, 0.89999998, 0.80000001],\n",
       " [0.40000001, 0.5, 0.60000002, 0.80000001, 0.69999999, 0.70000005],\n",
       " [0.1, 0.60000002, 0.60000002, 1.0, 0.80000001, 0.80000001],\n",
       " [0.2, 0.5, 0.70000005, 0.89999998, 1.0, 0.80000001],\n",
       " [0.40000001, 0.60000002, 0.60000002, 0.70000005, 0.80000001, 0.60000002],\n",
       " [0.2, 0.40000001, 0.89999998, 0.60000002, 0.89999998, 1.0],\n",
       " [0.1, 0.2, 0.60000002, 0.89999998, 0.69999999, 0.69999999],\n",
       " [0.2, 0.40000001, 0.70000005, 0.80000001, 1.0, 1.0],\n",
       " [0.30000001, 0.40000001, 0.60000002, 0.70000005, 0.89999998, 1.0],\n",
       " [0.2, 0.70000005, 0.60000002, 1.0, 1.0, 0.89999998],\n",
       " [0.1, 0.60000002, 0.60000002, 0.69999999, 0.80000001, 0.70000005],\n",
       " [0.40000001, 0.70000005, 0.80000001, 0.70000005, 0.89999998, 0.80000001],\n",
       " [0.40000001, 0.5, 0.70000005, 0.89999998, 0.70000005, 0.89999998],\n",
       " [0.40000001, 0.60000002, 0.60000002, 0.70000005, 0.70000005, 0.89999998],\n",
       " [0.40000001, 0.60000002, 0.5, 0.80000001, 0.89999998, 0.89999998],\n",
       " [0.5, 0.5, 0.70000005, 0.70000005, 0.69999999, 0.89999998],\n",
       " [0.40000001, 0.30000001, 0.5, 0.60000002, 0.89999998, 0.70000005],\n",
       " [0.5, 0.5, 0.70000005, 0.89999998, 0.80000001, 0.89999998],\n",
       " [0.60000002, 0.5, 0.60000002, 0.5, 0.80000001, 0.5],\n",
       " [0.40000001, 0.70000005, 0.60000002, 0.60000002, 0.70000005, 0.69999999],\n",
       " [0.30000001, 0.5, 0.70000005, 0.80000001, 0.70000005, 0.70000005],\n",
       " [0.60000002, 0.5, 0.89999998, 0.69999999, 0.80000001, 1.0],\n",
       " [0.30000001, 0.80000001, 0.80000001, 1.0, 0.89999998, 1.0],\n",
       " [0.30000001, 0.80000001, 0.89999998, 0.70000005, 0.89999998, 0.89999998],\n",
       " [0.40000001, 0.60000002, 0.60000002, 0.60000002, 0.80000001, 0.89999998],\n",
       " [0.40000001, 0.5, 0.40000001, 0.5, 0.60000002, 0.70000005],\n",
       " [0.30000001, 0.60000002, 0.5, 0.70000005, 0.80000001, 0.70000005],\n",
       " [0.2, 0.60000002, 0.70000005, 0.80000001, 0.89999998, 0.80000001],\n",
       " [0.30000001, 0.30000001, 0.60000002, 0.89999998, 0.89999998, 1.0],\n",
       " [0.30000001, 0.70000005, 0.80000001, 0.40000001, 0.80000001, 1.0],\n",
       " [0.5, 0.60000002, 0.60000002, 0.60000002, 0.60000002, 0.70000005],\n",
       " [0.0, 0.5, 0.80000001, 0.70000005, 0.70000005, 0.80000001],\n",
       " [0.30000001, 0.5, 0.70000005, 0.70000005, 0.89999998, 1.0]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies[900:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZYAAAD0CAYAAAC4swBzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJztnXmcHFd173+nt9kXjWZG1m5ZGsnyKu82trGJDWYxJjyT\nYAIEEyCOkxBDCC88Qz4JmCQ4QAjbA9uEzRgIjy3YgC1sbCLLu428SbJasjZrn9HsMz3Ty31/VM/0\nre5ablXd6qnuOd/PRx/V1HLr1u2qc+455957SAgBhmEYhtFFbK4rwDAMw9QXrFgYhmEYrbBiYRiG\nYbTCioVhGIbRCisWhmEYRiuJMAsfHh7mIWcMwzB1TEdHB5XvY4uFYRiG0UpNKJZ0Oj3XVYgU3B6V\ncJuY4faohNvETJjtUROKhWEYhqkdWLEwDMMwWmHFwjAMw2iFFQvDMAyjFVYsDMMwjFZcFQsRdRDR\nE0Q0RkSnlR2LE9E3iWgTEX0hvGoyDMMwtYKKxTIB4E0Afmxx7GoAB4UQlwJoJaILdVaOYZi5ZWS6\ngIFMvir3yguBfWM5uKXyGJwqYGiqEPh+h8bzmMqHM4f7lbEcsoVwyh7I5DEybf38BSGwfSiL7UNZ\nUzsOZPLYO5pDriCwdTCLXEh1m8F15r0QIgvgGFHF5EoAuBjAPcXtewFcAuAxbbVjGGZOuebefgDA\nfW/qQUPcUgZo43NbRvHr/Rn87RltuObEJstzCkLgrfcZdXroml7f93p5JIc/e+g4lrbEcdcVC32X\nY8WTR6fw0ceGsWFhEv9x8QKtZU/lBa7dOADA+vm/vnUMP9o1CQD48OmteMuqZuQKAu984DgyeYEz\nFybx7EAWS1vieH9vDH1aa1ci6JIunQBGitvDALqsTtIxEYcnN5nh9qiE28SMnvboAAA8+9IuLEiG\n28v99X7jXv/10hDWZ1+xPCcnSnXy83wz1/xmIAWgCQfG89rfm58dbAKQwpaBrPayB7MEoB2A9fP/\naFfH7PamPcdxSu4AJvJAJl/8HQeyAIAD43n87FgjlgWoX1+fvVoKqliGMPOUxq993GsFVEin04HL\nqCe4PSrhNjGjrT22HQUArFq1Cj1N8eDlKdwrmUrZ1j1XEMD2YwCANWvWwMaTYoncJltiE8DRMQDB\n5VM5bWMjwHAmlLL7M3lg54B92cU2BIDm1jb09S3D6HQB2NFfcSqFUL8Zgo4KewTAlcXtqwBsDlge\nwzARxIP8DhXZZgoSHolF5Hm84qXahWKMxS4aFWYTKCkWIvoVgNcBuIOIriei24qH7gGwgog2AcgI\nIR4NqZ4Mw8wTnASeHNcP4pgLU7GEKrA9aPiZ+LzdWIgw20DJFSaEeGPZrm8X9+cAXK+3SgzDRI2o\ndPBlGRlkYFOtTuDzZrEY/9s1EwVSzc7UavsyDDPPcRmV7IiXnn+tMuMCmwuLhRULwzCRwklfyEKy\nEKDHHaZeqVZ2Q7f5PjMxFmFTozmPsTAMw0QBWZkEcYXVg73iNnjBzRUWpvBnxcIwTKRQFfrBXGH+\nr3UjTKUlbLatmFE8dgo4TKuNFQvDMJa4uVrmArMrzD+1OtzY9PyKFosd7ApjGKbqyIK7mirGMcYi\nbwdyhdWmZpHjJW7PPzuPxc5i0VUpC1ixMAxjiWnOSESMF23DjesgeO82eME1xsKuMIZhqo0Xf37V\nCGFUWBRdfiq4KdaZGIvd4/E8FoZhqs5cyVvHmffStq6V34MvwG+masF75VFh1ifyqDCGYaqOrniG\nTnTVSb42p1uzhIiXwQuz81h4VBjDMFFB17pcnu/rdEzTqLCCVFA+KlpTAU8Wi8U1Mhy8Zxim6sgx\njKiIXl0Wi+xGy2u2WKoWvFeMsdidx8F7hmHmlohoFvM8Dv+V0rX8frXxsqTNXM5jCZroi2GqRkEI\n/OaVDM7oSmFxS3hJp7b0TyMvgHN6UtrK3DeWw46hHK5Y2oDDkwU82z+N1y5vBAH4zSsZnN6VwpLi\nM41lC/juS+NY3prAm6UUvbmC8fzn9KTQq5h06/GjU/h/uyawtCWBhQ0xCADtKcIbljehMeEsWmTB\ntPGVDJa3xpGMES5d3DC7fyov8MCBDC7sbUBXo9FPfX5gGpN5gfN7G0zl7R3NYedIDlcsbXS8757R\nPHYOZ7H58DRWtsVx+ZLS+XIg+tmBLO4/MIX1nQmsX5DEpkNTeM3SBjQnYnjglQyeP57FO/ua8eSx\naaRihOeONeDVndMYyORxYDw/W84DBzI4qzuFk9rtxeHxTAHfemkM5/akcNmSRuwazmHHcBZ5ASRj\nwMrWBE5ekARgFtj/vXsCr1/RhIY4YSxbwHdeGkdvUxzNCUIyBixtSaC7MYZn+qfx2mWN2D6Uw3iu\ngAt6G/DAKxms6UhgZVsCE7kC7twxgUcOT82W/cyxafQ0xXFWdwpbB7MYmTabXgfG87h96xheHMxa\nPhMrFoYBcN/+DG7dMgogWL5zNz70yBAA4DdX9yCpyV/wp781kqu2pzrwsceGUYCRZjcVA/719+Zn\n+rcto/ifQ4YAWdkWxxkLDQX3s92T+OqLY2hJEH75xh7Xe+YKAn//2DAA4KljZuGydzSPD53R5ni9\n3OH91kvjs9t3/kEXlrcaouPbL43jBzsnsLx1Anf+gZE7/oObjfb75Ru60ZIsOUXe86DRBl0NMZzV\n7ay03/+7wdntr10ax/qi0Jb57LOjs9ur2xPYNZLDloFpvHddK255xsiY/vM9k9IVjfhF/1BFOV9+\nwcgk6fROffiRQewdy+PuvRn8+HVJvO93lclyra7/wvNjODhRwI2ntuIzvx/Bw4enK85pjAOZPJDJ\nC3zxeaMut5zXMfsMD13Ti6++MIZf7suYrvsX6b35y02DsOL7Oydsn4mD9wwD4KWhXFXvF8Zoob2j\n+dmg6vahLF4arnymzVKv9BWpZ7212PMcz6n5bpxcPE/3Vwq4cuw8Tf2ZUsNsKZazfyxfcZ5dPfeO\nevsdD0ptYPdIu0aMMh89Mm2k79XMXun5BqecX4zyOv6+2EZWSgUwlAoAbB8stcv2IXNH4Imj9r+X\n33k4MZ7HwjDVQf5Ig/jw7ajoJXq4RbzKq5DYVU2uh1Ov187H77lVTZMZnU/VNbdlLu5BDs/pZDj7\n7f/wqDCGqRJhB3Xlj1lFb8nnxzX6LlRKsqufXI+YQ0lhCGC3IqOoWFR/Nifl4VSG3/4PjwpjGITr\nE57BNAw1ZMUCWAtKW0vB49ca1OBSWWPK2WKxLsFrtbz87HazzHUS1mgr4fDuOf30fp+YLRaGQXWS\nM8lCIxdG97fsIbzcwasrzKlslaLsFIOsWJx6vbaKWdP8Ez/HdeB1QqXqz2bu1JjvQQ4a3O88HFYs\nDIPqKJZqusIAa6uCbLa95ml36r0Hsf5UFYu2GIuHa6sxid5NeZUfVlYs0pUVFotDIVm/wXt2hTFM\ndQjbYjHFWFTOVxTiVoTlCpNjLE5VCsV6iIDF4vkeir+bcHj3nAQ1WywME3GEQ69RB14/ZnPw3tu1\nwV1h7tc6j1bSE2Pxcm011pP0HLxXLVfaLn/3nCzMrE9tysvmMwxQFV+Y/EGHstRHmYRwD95LI7Cq\nrFhUyi3PxCiEfsVstvLmfv0Vt6VUyttWta1NwfsyDekkqP3Ot2JXGMNUCfPIHP1CrPyDc7uFrIc8\nDzd2KNspGDyDSke4XDiZet02Ak/XcvdzhXeLRe13kxVxzkPw3m+MhV1hDIPqjwrTveotUDkJzqoH\nbvecOl1hQa6X5Vi5YglDMVdjmLkXvAbvVTEvsGk+5vTbs8XCMBFH/p4VV04JFdV4hhWBFYvtqK7S\ngQrFIm3bCbwwYyzVwLOLT/F3k11s5W0XTowlPFixMDVDdSwWOUYwN6PCzDGMEl5dYU7VV5p5rxB8\ndxo+HUb7RUGxeF3qx0+MpdwVFkaMhRULw2AuJkiGfz9XEWWKsegrW0VHqcjP8rk1KvOA6j3GYhe8\nd2ty+XXz8u6xxcIwQaiCZjELxhCC9w4xCTc8K5aQ5rHI5TpZLHPlCgs7cZffGIvrUGkHa89Jz3CM\nhWEiTthrhalQlZn3CtfbCVBZjjnFWOwVs/+GVVGWYVs1npd08TFBsrztnW7pf1TYHM9jIaJbiWgT\nEd1JRElpfxMR3U1EvyOiB4hoUWg1ZeY9qsM2g6DS4w5CgFXzQ+1hesJpVJgcgNbkCvO6WkHYHkzX\nQR0+5bUcuym/h5OV5DvGMpcWCxGdCWCpEOJSANsBXCsdfgOAF4QQlwH4NoD3hVFJhqkW+bCD9/Jw\nY5tzbIP3Xlc39nZ6BSprfTkG76sxDd4Cv4mvVLGfn2Pc120CpR0ma6+s8Z0GDPiNsYTprlJJTXwx\ngI3F7XsBvBfAD4t/7wRweXF7AYB+nZVjap+jk3l8c/s43r66GavaExjNFvC1F8fwxhVNOK2rMt3s\nDI8dmcIjh6exoIHQ1RDDW1Y1m4TYr/dN4sB4Hu87uQX/98Ux7OtvwuLJUXzw9FbX0VNCCHzlxTEI\nAfz1aa2IEWFoqoDbto7hbCnP/c93T2LPaB7Xr2vBA69kcPu2MVyyuAHndKfw+NFpdKQI9+3PYG1H\nEumRLA5PFHDJCSn83ZntGJ4u4Ac7J/DedS2me8s1u29/BpctNueFv/+VjEmgP3lsGp98egQ3nd4K\nOcv9f++ZxPBUAX+6rgUFIfDlF8ZwbDKPlmQM7+xrxkiO8Jf3D9i2wY7hHI5O5tHbFJ9t7489Poyz\nupNY1BTHh05vw092W6e1vXHTIGKotAwu/8VRkwWTFwJ7R3P4xrZxZCS/4m3bxvHCYBbp4RyOThql\n3LC+BXbcsW0cTx2bxk2nt81mrHRCzmfvhdu2juG3BzIgAg5PFLC+M4HJvMDVK5tM533+uVHL6z/+\nxDCOTBYwWWZu7BvL469tUgfLPNNfyhq5TcqW+qNdE3h51P6ZPvX0iGvZVoRpAJObdieimwFsFUL8\nnIjWAPiUEOJPiseaANwNYHGxnucLIcZmrh0eHhYAkE6nQ6o+E3U+u7cFOyYSaIoJfGndCH5wuBG/\nHTSE6R3rh22v+8C2DtPfd6wfxo+PNOK+42ZB/I5Fk/jBkdKH/+dLJ3BeuzmtazmHp2L4h5eNfO+f\nPGkUSxoK+M+DTXhs2DoP+61rRvD3O9sdy5S5sH0aL44nMJqPYXWTISB2TRp9uPctmcB/Hmy2vO6O\n9cMVzy3zzhMmcdfhMiHXN4KxPOEfXy7lr1+QKGB1Uw5PjTrnlV/bnMNHVxq57Mvve9PycXxxv72w\nV+HdJ0xgIBvDrwYaA5Uzw8dWjuEze1tdz1vdlJttb8ae9y2ZwIUdzt+KE319fQCAjo6OCh2l0vpD\nAGa+qg4Ax6Vj7wHwsBDin4jobQD+AcDf21XAL+l0OnAZ9UQttcfx3f0ACpgsEPr6+jA1OATA6HU6\nPsO2o6Y/+/r60JUdA46be9HUthA4UtrXsnAR+k40C99y4iM54GXjNV66fAXWdCQxfmQQgPVHtnTF\nicDO45bHrJhMtmA0b5TVn08WXQ5GB27xCScAB617mH19fRXPLdPb0wMcHjPtW37iKgxPF4CXSz3i\nwVwMx7Lujo7jhRT6+pYYf5Tdd9HiJcB+e8WvQm/vIkyP54EBa8unnGQMyDq4zxYtXQbsHXIth5KN\nwGTO9byoEqPqrNIcp+Cy2Q4VN9sjAK4sbl8FYLN0jFByf/XDUDwMUzXKvz+v5r0o+1/lHm6UB7Tj\n0g5diz/O7hP+hZCTs0LHiLiCEJ4mEzopFaAyttHdaC2+/MYcosKGhfYuYp3E5nJUmBBiC4AjRLQJ\nwKkAfkJEtxUPfx/A1UT0EIBbAPx7WBVlahOVxFZBKC/Pa2ZEoaBZgq7gEfZoLqs2FQE96F5nl1uW\nAb0jtFQHU7gpKMbA67woLyg5IoUQHy3bdUNx/zCA1+uuFFM/lMfRg4grle9AaUa5xbbTnA+vMrZc\nkZDtH96wqkZe2AjvgHpBh8UihN6OhGqdypdDYawJU7HwBEkmVMKeehFUhKi4wrxSPt9GHqUW5IOz\nVizCxmIJhhZXGPTGClQzembnamZrjRGm8GfFwlSVQBaLgpZSWlzRwmTRGWMp7wlqc4VZVCQvKt1W\nMetTK3Bqz/J5FH4w0gLoQ1VfTLMrTIk4zfHMe4bRhu4YS3m+RZ+uMMcYi9eZ4uWuMIVJkSpYXZsr\niApXmA5FpiNlgJXSC4JqnWo9eF8teK0wpmYJPcbiI3hvpVicOrlBR4V5XZLESz3yFqPCYqTBFabF\nYhFaXWGqdarGqtT1QNz9FN+wYmFCpdrLWyndT5JPMx1q56G33qSj46iwAILWqhq5QuX+GAVfXlBX\njGUuXGGsV9Tg4D1TN+h2UlTMY/HoClPBaw/YaRVi3c+fF5WusDgFH42la1SY1uA9e7i0EuMYC1Or\nVHtUmF9XmNMn5tVnX31XWFnwXkeMRYNGKGgfbsyaRSdssTA1TFmGwQCywcoQ8FOcXIfZFWk1zkK3\nyyAo308XeUtXWPBydVgHBZSUQUJDneZqteR6hWMsTM3iJ+eDlfAVQm0uOSnc0HJUmAOBLRapTkHk\ntVU1chausKjEWIQojdlLatB2bLHohUeFMXWD0wz3Gaw6pgIaR4XJS7oonO89xuJ0b29lma+tvDhv\n4W6KexwVZjUkWIcQlydIJjV0j3neo154HgtTs/jpFFkJcrtPIHCMZXZUmP1H5jXeIM+8L1eIgSwW\ni325gqgQuF6HG1u1t44huwVpgmRSQ7pCHkasF3aFMTWLn0UorXrLdtdV7PYov1TmsWQ1TpB0rItL\n41jpN8NiKZskCnjSLFaWgBaLRRoVltAgadgVphd2hTG1i48Jkl5cHn5WN/YqnryuPSWPtiGoWyxu\nHXI7xWI53NilLKDUdlaLNuoIlAtpxFpCgxRji0UvvFYYM6+wEmqqrjAV+WUeFVa5rxyvI6QqRoXJ\nS7o4lOXWIbeKheQKlYtQGsF7dUFu1d56JkiWImpaRoWxwaKVMOexuKYmDsJMauKg1FLGxGogt8d3\nd4zjm9uN9LKLmmL41Hkd+PQzI3jP2hZcuSx4StipvMAHHx7ERYtSuPiEBnzq6RG85cQm/GLPJPYX\nc4svb43j3y7oxOKWuOmajlQMTx4r5Sg/uztpyut9dncSiRhhWUsc9+7PIJMTWNuZwD+e24F3lOVr\n3/imHnx/5wS+/dK4a53/5fwO3LPXyFf/xYs70dMUx+bDU/j8s6MYnCrg3J6UqV5hs6Y9gZ0j0cxo\n+O61zbhzh1qGxyCsbk9gl+Y2WNIcw8GJ+jNjyr+TsPjy2mGcfnJwueo3NTETYWaUCgAcmSzghv8x\nUtR++pkRLYrl4UNT2DGcw47hHO4/MIUD43l89UVzetz9Y3l8besYPnWekUB0U/Gacso/lpm/n5D2\nbR/K4bEjUxXXeumh3PxEKaXutsEsepri+Li0r5pKBQAmI9zVroZSAfTEWMp519oW/NuWUf0FzyEN\nceDGU1uxbzSPW56xTmGtSmeK0JyI4eBEfnZfnAzLb017Ag0h+qvYFcY4IgdMnYKn8rGgk7Yt84sI\nfyPMoiDT/cxwvmZlk/6KAHjvuhYt5Vy/rgVtSfUHC2OW9xtXNOE3V/fgI2e0VRxrd6nb+b0pvO0k\n+zb+xmULAtfvHWuaK/Y12/gEV7cn8OCbe/DrN/agryOJK5Y14hNnt3u634eldvj6pQvw06u68dEN\npX3/8apO3PumHjz45h7ccdkCX3PMVGHFwjgiy+WYomgP44W1ncfiQhTWl/LjbU6G9GXqKrch5k1Z\nJEKSYskYWVpDrS6KheAs/OIa6mvVPnJdU2XbRGRaZ86rMpbLAxmxNrmIGBntRURKE4mDwIqFcUQW\nimGuLWTCcukWfyaLjuXfg+KrBiG1tdMCmV7wKpzCcIXNYDVgI+Xysgo4r9KgYyiuVRXkuSNuqxF4\n/alSUnkzW3IZ1VxpnBUL44jJYlF8M6u9VL4TkbBYfFwT1oepq3MQI2911DHc2L4ulWU3uCkW4fw+\n69C/VlaPnUViNQTBq9UkW6NU9n/5vcOGFQvjyJwoljqLsfhxhYUlAnTJ9xh5E746hhvb1sViX0rh\nQZ3O0CIYLW4gVysu/WH1jnhtMjflHeaEyIp7Ve9WTC0iv/DKPZ6QYix+iMZsbe91CMsHrk2xeCwr\nTIvF6n1LKMSAnKqkpXdv8bObFIu0bdUB8tpkcUmazxQnF1FFg4UVC+OM/L5XLcZigd/gfRSWWvdT\nhfAsFl0xFq+KRcttlYmT8/sqIEJ3hVl1J+Q6yW1iNZ/Qax3kARKzikXaV82fgBULo0zVXGFWBfg0\nPKJgsfhyhYWkWbTFWOAxxhJid9mqfeNErlZS6K4wq3KldpDbxKrz4bUO8m870yZssTCRRP5onV5M\n03ka7zm7z+X+dkRhfSk/cZ7ox1iiMyrMauCfmyvMCN7bnxCWELZzhVl2Pry6wizOl59DdbqADlix\nMI6YXGFVmsdiJYj9jhqOQvDea6IwILxAq64PnjyOCgvTjWqV44dc7unWUdFRX6tfXf5dZYvKMgeR\nRQFO85Dk8qxiLBy8ZyKD6qgwnT08HfnWZ4iCKywKVtMMumIsnkeFhSjV7F4Xt3s6KQ/S0Lu3ipvI\nQ4hNw40VO1NOQ5DdXGGsWJjoIH0c1XoxrawMv+ohCkLdall6N6rhigkCeSwrzOHGdorF1WJxKFNH\nO7l5t2ImRVB5trVisb+fpSKVdnGMhYkMczGPxVKxCH9B8Gi4wrxfE17wWF85XuoYpkyz+4mdevfV\nmCBpeV/5HtK2XTrucpzqbLaARMU9eFQYExnkF151JnBwxVL5SQlLT7o7fqwF3URgVZlZ5ip4r/pS\n+KmfrcXiIN0Mi8X+ZmFZLLbnWrrCrGNHdphcYRbn88x7JjrMwVphdu4rP/I5CvNY/BCWENCxuCLg\nfYKkaszCzztmJYABd/eb4wRJ79WowE1ZyIeVB6x4tLJMa4WxK4yJCibTXdUVFvANtlo4UpRXRrWs\nCFgsfghLBugqN+ZxgqQqvhSLbVnOhc21K8y030qxWJznJLDlzoilG83hWt0o3YuIbiWiTUR0JxEl\ny45dR0S/JaKHiOiicKrJzBV+YixBsY2xaCqrFoh88N5jjMVDyZ6vsJv35OQKA5zbWMecD6tXz66f\nY2V1WVksTp02+UjkJ0gS0ZkAlgohLgWwHcC10rHFAK4BcIUQ4nIhxKOh1VSBiVwBmZCXsx2cKlSM\n4BiaKlS8GINTpf5GQQgMFf8WQpiOlTOaLWBakoYz52dyAhO5AqbyAqM5wqhCRNhqpMnIdAG5gsDo\ndME0v2IiV8BkzqhnJicwnjWe8+hkKfvc6LR92w5OFbBnNIexbAEj08H8T4ele85QEMD+Me+pbXcO\n5xzbO6pUUQb4guBNUIX5PLbDjd0mSDqUGZYQtnsTreexeIuxmEaZze4jy+Nho5Ka+GIAG4vb9wJ4\nL4AfFv9+A4BpAL8hokMAbhRCjFUWET55IfDGX/UDAB66pjeUezx0MIN/emoE165qwgdPNzKzpYez\n+MDvBnFeTwqfvagTAPCz3RP44vNj+MD6FryzrwU3PzGMx45M4+uvXoC790zil/sy+MwFHbhwUYOp\n/LFsAW/+dT+6GmL46VXdAIB/fmYE9x8opeptSRDGc+1Auh93v77bsb5f3zqOG09tnf27P5PH2zYO\noLsxhv5MAd2NMfz4dd0oSG0n886+Zvxo1+Ts388dt8/DvXUwh+sfPO5YH1U2H65MHfz2+wd8lbVj\nOIe33lf5bFEntAmSmsptSpCnXn1bKrwYS5OFBmlJxBw7Qu3FtL0661FZh8pCGqWCF0i5gbsb4xXn\nWi3971QteYkYq9WdqznzXkWxdAI4WNweBtAlHVsEoBvAawHcCOCvAXymvIB0Oh2slgplZPIA0KHt\nflZ8c3crgDh+snsSr288DAD48dFGAA148tj07H2/tr0dAOGObeM4Hwfx2BGjXv/v+cN4YNBQJt99\noR8LR8z5xndOxAG04vhUYbas+w90mM4Zlyyy323dA6AVdvxo1ziuTB2a/fux4SSAZvRnjP5Rf8a4\nj9Gh76i4/q50dfKhM5UsnzqMtc1N2DGh8om6c3V3BlMFwuDhA3B6Z8pZ1ZjD7kxlHTqG9iGTaYGV\nCOlIFDCcMwvtc8VBPN/RhMeGU6Y63dPfaDqvkfIYV3CyfXj5+Ow3clIBOLutGWe1ZTFdAB4dTuHC\n5DH8KNNUUb/mWAGrm/O4pnUEbZMCi1KtODJtFur/58Qx7N41jNd1NWLj8VLnb0NrFue0Z/HMaBK/\nHzVFBAAAl3RM42Hp+c4oHER7vA0j+dLzXNA0CsomcXZbFme1jeDRI0b64bd0DiGdNneeFgngnLYm\nPD1qlHndokncO9CAGVvrpuXj+O1gCr3JAgSAgf27cN2iFPZm4kj270F6ADgwFQNgdIL37H4ZAwmz\nsg0iK/v6+myPqby1QwBmki93ADheduxBIYQgogcAfMJrBVRIp9OuZYxnC8COfi33s6Px4HEgkzPd\noys7BgxMmPbFdhybde739fUB244CADo7O4FBwwJobm5GX99SU/mZgWlg75D5GYrXWrF02TJg35Dt\ncQEytcXL+yeBg6Omc/r6+oy2e6n2evVh0p4kjGSd3ao/v6ob3985brLq/HLrBR24+Ynh2ZjQpaet\nxqWnAdc/OIA9o5WuQSs+fnY7/vmZEctjf/eqFQCA7YNZYO/g7P6rljXivlcytmX+zdndOKvbEGyX\n/8J4F5MxYN3aPrQcGwQmK63YL13ajZVtidnze5tiWLe2D59ZCzw7MI2bNhvv7IcuXI577jk2e90p\nCxI4OlmYnfhzTncST/eby//Ttc34s5MrFeO/ryttv6/4/6/HhoAJs/V7Tm8Tbjm/1In6r7XA4Yk8\nritaxJ84ux1XLjM8Hjf3ARuLz3DhohQ+c4Gx/91SeX947zEMFS2jT1+2bPaZr1zagNPW9eEX64BN\nh6bwD08OAwDOW70Y719YUj4PnTKzZe1l+fxa898PbOyfHTb51rNW4a1l55dLvuRoDnjZENmrV5+E\nDil/sYr+ut+GAAAgAElEQVRc9YtK/O0RAFcWt68CsFk69jCADcXtDQBe1lc1b8xVjNbKuLQ1OC2W\nXAiC1/kRdudHaZ5FVFB2GelqOwpelIr7pjyg7RZL0DE7XXWBUoL5XQw68ELVnSV7xLzGVlROJ5tt\nPwSpX6RGhQkhtgA4QkSbAJwK4CdEdFvx2PMA9hPRQwD+DMCXQ6yrcz3n6L5WH5fKB6ejvl6Vk92H\nWqsjp8JEZR4Jkb9cK5ZlaShDSbGUPZfbu2o5N6Lsf5VrrO5vdW95eHjQDo/VqDCrutmt32W6LkA9\n5OcMrFg01SNslBy4QoiPlu26QTp2s9Ya1TG6f9eCR/Vk96FGYXZ61FDujWu6H2koTGXyo9egtB+L\nxdEqcRCyBCqzWII1iOpk0HgQwU8ELz9cNWe/AzxBMjhzJBvdZruGiXdXmPUFtTo7PUxUFIsOZVAq\niwIXpVLn8oFQQV5Vu9n0bu6u2W2LD0V+p4NaLKo5YOTz7AR/kKrotBS8lmV2hVVPs9SPYpkjvMRY\nTBOYLI57fXl1xVjYYqlE1XeureV0xFgUvmavS7o4nR3GEj+ylVKtGIvcJmGIXpNwD3gDr8v5R3aC\nZK0gv4NWE4vCwu9vpaOKXovgGIs6SkJJgzKQigqMSiI2r8rAqgc/s8tOUDlmZnS5X16nxeLDFRZG\nHMLJ/RekLK/ncz4WH8gvYVhyUn2tLPdzPK4vZ4kui4VdYZUoBe/h3EHwtkhjcFQsFp0Jt/zEWNz8\nZGZXmLeZ5+WotAdQFmPx+EyeR4UFtli8nu88WCIs6kaxyFSzA27lJ67W7+fVMrOLsbArrBIVAeB2\nilMaWdX7eRKkSqPCPBQIf6PCHFfgdbmf3uHGat+m/A2H8SnIwr3ao8LMMZbqUTeKpRqiUTWeEqR3\n4wWvhobd+ewKq0TlwyAXV5iXeAbZbHtB5X6qAW2VuthZdarBeyvk9rSysL28qn6yVtp9C0E+Ea0j\nswJcH3TVcS/UjWIx5TmooqD0oljcCDt4bxtjYVdYBX4m/5Xj5T3Q8c2r1FlP8J4c7+eoWBStmRjp\nGG7s7f6Ady+AZ1eYp9Ir8Sqw52x+3xzdt26wHm7s/sVpCd7rirGwK6wCtRgLOea19OJ20iF81BSL\nx0J9uLV0KMk4aXCF+Qgq2N0yyCOZA+jBGsfr5Xbu77CpG8VSjeC9FX4tFrc6qvScvH54tjEWtlgq\nUBXATj9BlefCKaFjguTMPt3BYLm4OGmYee8QH7LD6z11xOLqkbpRLObhxtW7r5cJknIQz20ei4qs\n92ppsMWijqrAcB4V5i/G4lcSqfyKXv3sfuIlQWIsM8SIqjaPRSaMPlaMrLd9leXxfHaFBUTMkcWi\nE5PVpfAQXi0Nuw815NxoNYnSzHuXc7zFWIKPHAplRJNDZeziNY4pfxWfLkbB3Th+hlaH3ccKHLv3\n2DFgxRKQuRoV5vt6iwp7HWqZ1WWxsCusAtUPw+kX8DuPxe97FsYq1X4D8UGvidm4wnQPvy4njDaU\nLddqz2OZK2dE/SgWj719XVg1oJ1AMbnrLESS12fwarHwPBZ1VCdIOpehpy6qhBGotbIwZprGflSY\nvweXmzyO4MF7PxaLrjaUS9E5KiyKcTsr9KSniwDCZtuKZwemMZ4VeNUJDY7nTeYEnjw6hfN7G9Bo\nMyjeaQKZEzN1fPzoFI5NFnB6VxK/O1RKuHTPvkmc3Z2yvrjIXelx1/t88flRdDfGcMkJDXjo4FTF\n8UcOT+ELz41aXDm/UXWFOfVw/Q439is8wjA8VYcHq16jSjxGyAfULH4sljC6WFqXdPF4/lx1GetG\nsaj2NMayhdkMdt+8vAsntds3weefNfLNX7m0AZ84p8PmV/UXoBUwFNzfPzZsee5XXhhzLW/YIaf3\nDD/bbWQ3vGObtRK6+Qnr+893VFc3dvoFTutK4siBSmVuV5YV6xcksVsxg6ScHVCV7kb1a9Z2JLBj\nOIczuoy0vG7zWFa0xrFvLI9Tu0ppfFuTzg07c83pXUmM5wSeODqN9Z0JbBvKKddzBqu+oNP3DgA9\nZbnnZ1xyq22uO60riYcOTmF5q/k6+T5ynnurPPZeOLkziR3DOXSm1Mpp8TNLVAN1o1hkDDeTdYOO\nSelmR6ad+3j3F4XC/Qem8IlzrM+xHI6p+FvuHPb+sdQaN57Sikxe4FsvmRVbS4Iw7jBqoCEOvGF5\nE36+x3va3yXNMbx5ZRN6m+O45Wlzqt6rljfivv32qXhnUBa30iPcsL4Ft0kK/ENntOEBVcVi06v9\nq1NbMZkTGMgU8NxxI03vCc0xvO/kVgxk8rh96/ispXJiWwJ/d2YbljTH8WD6MO4u5pP/5uVdpnt9\n7qJOfO3FMXykeO53dkyYjv/vDW34ty2jFXX51ws68Ot9GVy9sgmA2V24IEUYLOvofO6iTmzcn8Fb\nTmya3dfbFMfHNrShy0ahydfkBXDP3km8YUUjrt1opA720gOX57F84VWd2JQ+hLev7rE896uXLMD2\noSzO6THnsv/Oa7rwP4em8LaTmi2v+8gZbVjTnsDrljfOnr/5sPn8VW1x/NWprUjFCT1NcctyVPmL\nU1uwqDmGP1jSqHR+j0t7h0XdxFhU3QDy0FodZqIXVxiVmSzV9sFXmw0Lk3j7mma8Z11LxbFvXFYS\ndo0WvbiPnNGGD53RpnyvJQ2lXv0fr27GO/pacMXSRmxYWBIUpyxI4GMb1MpUzSApv0Pv6GsxuV/a\nyhYLe/vqkrD5SNmz2d2tJRnDP57bYWqLd/e14LXLGnHdmhZ87Kx20/lXr2zC2T0pXNRRyvW+tMUs\nzM7tSeE/L+/CKQuS6GyIVVgtK1tL/U25GRY2xvGutS3obIhV1Pl26fecuaa3yTi/rcySev2KJpzf\nW+mGprJrOhtieNfaFixs9CeM5d/ixLYE3tA9jZSNxXBqVxLXntRcMepqeWsC7+xrsbU02lJGHXuL\nCmNlWwJ/0tdiug8R4Y9WN5sUrF+aEzG8s68Fi1vU28SuvcOkbhSLauBbDnjrGAFiPYHMXSgJeF9e\no9ZwjD+4+J29/jR2v3m58lYdrqmeQdJ8Y6dnls91Srjl1lkxH7e+oXyK1w6Maipdu/kZUXmrw86z\nwthTP4rFZrucvKICUsVvBkmB+rdYnISsSRBpaAe739/viBzlGEvZM6q+UuUjltwUrZ3gtl2CJICg\nVz3fNIpLgxDX3c+Sl82v928tatSPYlGcIGnKUOciBlTeRWuLRY0wMvBFCaf2DbOHK99Vdml56Uco\npya2u97y/NIVzkvqV5ZsO4Td5qECtamNJVKO7IzR0VHQPVo6oaFOjD/qR7HY/mFGngzo9iKXv4s6\nhwqKeRBjCbLyb6Cmke7rt42VOhVkn6fe6r7yrvLshm6WlV/LC/AuVGWh4HipTecgzNfaS9myFVXv\nnbioUT+KRdFikQciucZYfPZaVd/hoCudRh1nV5gc3Ax+L1tXmM+yVX8bL4pFpjLG4nyBXXuprMYb\ntiIqv4nfNg/TFeZ30ibjj/pRLNInpuoK82p5WyoRnzEWoP57UU7z29wEn+fgvc1+vy940HwsVopJ\nPtUxxuLyTnl10QaJsThPkIx2cFx2hdW7dyBq1JFiUcPLqLAwYyzzI3hfvRiLncXqN4itPirMGrdO\ng9O8NatDduWFs6IxWW5Xnme37e8X1f058KiwuaN+FIviaC/ZYnGbre9bsdhcaHJhiPk93DhmJ5U0\nIP+scb/Bex/3Ml3v8kzJcovF5T7ezg6GqjK2s7Ki8lYneFTYnFE3ikV9gmRp2zXEohbBVbxzJfXu\nClNVLNYjqLwhbK7w28SqSt9vjCVe9tBu59uNugplqXzbPxSvD/G99jTzXqoIK5bqUjeKBYoKQ/cE\nSVMVil+53TtsGhWG+n/ZnWMset0UfgW8HUGFo1vwP+lw3HqCZPXcOn7clFEMjsd9PAejh7pRLLLF\nouoK09Lbk+fFFDdVRxTVu2IpKM5jsZKkQX4aPaPCFO9l5wqzOtdp5r0Xi8VUZrioj3D0fo3fe6li\ntvLq/GOLGHWjWMzBW/vPTZ7H4uY+Uw3CW227XiecalkfqC4prz14L89j8Vme3yVdnK6Xe/WOS7q4\nlReyjFSd7Gh3KCodJtYlc0f9KBbF8zwF78teTCtzX1ZOnl1rda5ZlIP3FgSRCXYz770QU6yB3wmS\nTsF7twEhJosl5BiLcvBefzWs7+nhXNXfkNFP/SgWxfkpXiZIVryWVu+pRU/ZNsYiB11R93rFMcZi\nt4ChX1TWzPJC0Dq5Dzf2Zgooz4bXgGrSMTtvZlQshajUYz6ipFiI6FYi2kREdxJR0uL4/yGip/RX\nTx2TS0p1SRfN952JKai+0GHk144SThah7m9e2Pzld+RdGBMkZbzGWOwEdxivkJ+BAjo8ddpn3rNi\nmTNcFQsRnQlgqRDiUgDbAVxbdrwNwGnhVE8d1VhHzuQKcyvV/c00KRYXi8XuunrFedl8Z+EVKHiv\noXFVhZwXV5h55n3Z/VyEuZ1bJxTFElAgszxnVCyWiwFsLG7fC+CSsuM3Afiqzkqp8v30OB4+ZGTo\n21rMrgcAG/dn8N97JpEXAt/YNoYt/aWkR08dK21/7tlR3Pz4EKbzAr/eN4mf7p7A7VvH8PzANIQQ\nyEi+nKGpAl6Q7nHP3kl8+YVRfO3FUgrhLf1ZPHpkCjukzJC/3FvKgJiW9ucLwG1b3dMP1zKqFpmW\ntcJshpv7dWnpmiBpd/vyeTKegvcqFQiAuS5qw6LN2/4aXfeQ5agMIpiPqKQm7gRwsLg9DGA2VRwR\ndQA4XQjxaaeXKZ1OB6mjZRn7MjHcvtvIqnfH+mHctq1j9tg3thvpYfuPHsH3Djfje+kJ3LHeyO2+\nZ7AV8oLfjxyZxu1P7sOPj5ayu31/5wRuWj4OoJT58FOPHAJQ8gJ+7tnRijp+4snK/PGflc577EhJ\nqe0fV8tjXstc3J6Z/d2aY22YKJTEtbHf+M1y2RzKRXnD8EGkMwV0J9vQn3UX8xd3TuNXA0a61gUT\nR5BOG+27Mp/AzO94emoU6fQAlja04sCUfQa+JAksyfYDaMGCRAHJmMDR6crz0+k01saTeAzNWNWY\nQzqdxhmtzXhuLIlzmsaQTh/HaxY04reDRva+jkw/ACOL5Mu7ds4+PwDs2bMbF7Q34vGRFC5qm6x4\n3wsCiKEdBRDGjx1Euvj+tGZiANoQhzBdI2fAdfv+LmhpwC8zpVS3e/bsBmBkpty9+2UMJKyVV3Is\nCaAZnYkCdqVLz+Ple1/e0Ir9xd/i5PgQ0uljNmcaZQ8cP450+pBS2ZP50nUzddIhi+qJIO3R19dn\ne0xFsQxh5i0zfqXj0rEPAfhKkAqokE6nK8oYPjYN7B4qlb/taMV11N4NHJ4w1aHl4HFgypxrPtfc\nBcCcW71p4QnA/pJSOJxvBFA7yuAjZ7RBAPj35yoVoCq3nNeBroYY/urhQQDA8pY43r6m2VKpAsC5\nPUm8e20L1nUksX0oi9O6krOLLf7XygI2HZ5Cd2MMS1viWNrSO/ubpVIJ/PgPFmBwqoCFDXEczeRx\ncmcvAOBbJxawZySH6YLhxhydFvj0MyMV976mZwoXnbQI7SnCmQt7Z/evEQKrlmUxXRC4YFEP4kT4\n0vI8tg3mkCwK34msQGdDDF0NMTx/PIsNC5NY2tKLvpU5rGyNI5MX+OuHB3Fk0jxAva+vD6uFwLnH\ns1jTkUBzIobPniSKz27c6+bVAq8+PIXuxjjaU124/YDx+fStWYOv9eRw4yajbU9atQq3nBzD1kFz\nu8l8e0kOA5kCNizsmbUK+gAsXZbFCc1xdDYsmj03nU7jO6/pQipGWNzSW1GWzIdXC/zynpJAP2nV\nKmCnkWN+9UknzaYiLuckIXDyimmsbE1gUfMJ+N4S47ta1up8P5nbVhmegIY44fSuHvvYVPFd6erq\nQl9fq3L531qSQ1OCcEJzr6Ucmc+E2R4qiuURAH8L4LsArgKwWTq2BsBFxZe8j4g+LoT4Z+21tEAo\nuACsXlIr94yKM6HWZp1csCiFBJFvxdLVEMOli815si9YlMIpCyrGbsySihHOXJgCAGzoTpmOtaVi\neOMK65zfBKC7MY7uYm7zLikHe1syhtMXlsoamqqcfUQwArXl9QUMt8y5vea6LGyM45LF1hbLyrbS\nJ3Fal/GsbQAuWtSAn++ZrDg/RoQzpPo1xEttABirGF++xLAG9o+VOjREwDIpbzkRkIpTRbvJrGhN\nYIWFTD3Z5jeRn8WJRIywvDWO/WNGx0nVgxQnMuVSX9aqdj+Z5kQs1Hzsq9q914kJjmurCyG2ENER\nItoEYB+AzxHRbUKIG4QQ7545j4ieqpZSAdTWBrP6QKxGKuUUggG1NoIrRsF8zFbXxsnZC+63iTzN\nTXCZHxIWOkYYyUXEEK3hsKa6aR4Kzsw/lNS5EOKjZbtusDjnXC01UsRvzNJKITnNt5i9n7/bzRmE\nYELBLoDsJAyr0UZzJeh03Lc8wC3nn4yq/I5avaJWH8aamp0gqWJBWA5jtbiuPi0WCtQjtrZYwvqw\n1Uu1FPBVkDZhZPuM4qRCoOxZI1Qvpnaoa8Vi9VH4tVhqTbEQgv24VoIu7mKx+DVZvFgDc7WKbhiT\n7aKagVHHZEdmflPDisVdiqlaLFaKpXyXymCBKOHmtnK93mJfnMjxhannGEsYLrioxi/YYGGCUruK\nxe91foP3Pu83V8QoWIZKq3lJboLQt+r1UM1aDt47EaV8JnZrgDGMKjWrWFQMCMtRYRb7rCyW8mtr\nzGAxLJaA11uWGYpLKNi51RB+8RDMiygJcB05bBhmhppVLErDja3Wa7J0hblrDZU4TJQgULDhxhb7\nDFeYfaF+lW9QV1g1CMNi0ZEcKwxUl3RhGDtqVrH4Hm6sGGOpuJ+/280ZQa0Lq2tjhFAkoJd6ztGg\nsPBdYXMsv+3msURNrdTadzhfqVnF4jt4b7EvZ2H+lJ+ncr8oEaNgP661xRLOC+PJFWYhgashlMMY\nbhxlAT7DXCs8pjapYcXi7zor6ySnoDRqcbhxkDzfdsF75wmSNdZIHghnuLH19lwjuzujVC8gevVh\nrKlZxaK2vleJmTiK1bDhvIXFUhG8V65ZNAgjA6Lrki5ViLGEcb0KYcR2gij+MInqxE2mdqhZxSJb\nHnZzTORzZpSH6qiwSleYp+rNOYGFtY9RYb7nsdSA9ArDFVYLzM+nZoJSu4pFkvR2I8RkZZCbtVgs\nyrLYWa5IaizEElhY28VYwmiH4MIrfPEXdvA+Sq9XVCduMrVD7SoWk8Vid46Qto3/rSwPq+B9ruy8\nWpsgGRRri4UcLTf/FovPC2euD3a5EvMpf3qU5tcwtUnNKhZZ8NsNF5ZjJ7OuMEWLRWVuSz1jNV8l\nTuG4BMNw2+lmPlksvKQLE5TIZ8EZmS7g1j0t+KPGSVy1vAnf2j6G7+yYQEeq9MofsEnz+/2dE7Pb\nf3hfv+09Dk1U2iNfer6+89G7Ybm6ccxZ4dazLg6yPE6tEdXRakztEHmL5Yc7J7BzMoF//b2RCfE7\nOwxlMTxdkmKff7YyVe18ZFFT5c+5vLWUpfCaldYZHK1478kts9vn9hgZCs/uTmFRcxyJorRZ3Gy+\n3/XrWuCF9xfv8efr1VPNAsCJbXEkY8DfnGZc95Ez2zxd74eZLJQzWSXXL/DeJ+ttMuot/yaLmmJo\nihNak3Mrwm881WjLvzilBQSgI0XoSFFkBla8dpmRZfJ1yxvnuCaMChTmqr3Dw8OBC//yC6P4yctG\nStiHrunF5b+ozG1/Ylsce0ajl4/+7O4knunPup63pDmO69e14F9+H0xBbnxTDzJ5gZYkzfaw80Kg\nIIDJnEBbkvCau43c5t2NMdx1xUJM5QWaEsbyL1N5gVSMkBdGit0ZhBCYLpT2ZQtGmYmYYaVMFwTi\nRKZrVJnKC8/XFYRAXgDJGM1eX4185kb7ANmC8ex+RoplC8K0QGheCAgByxz3QfDTHvJvMbMwq+56\n+aX8HfQD57w3o6s9Ojo6Kn6UyLvCovFa+6OrQc0gbIgDi5qDG4+pOCFV9uHFiRAnIJky70/GjI9U\n/lCbi6ZI+UtBRGiIy9eanfBBhI8fQRGj0jpoQQSNV2bulYq7nOhAMlb5+0TlJZfbMioKZYbyd5CJ\nNpF3hdUy5ULEDoHqy5Zam5fDMEztEHnFEq1+kzcSHlrX7jnDen7WKwzDhEXkFUstYzeSyMp7Yxck\nDUuxsMXCMExYRF6x1LLFkrRpXSsXma3FElIDsGJhGCYsIq9Yalmz2AVArRSOnQIJz2JhzcIwTDhE\nXrHI6+nW2mx4uxiLlcVi90OEZrGEUyzDMEz0FYuM1fL2USZhoxXKLRbhMCwsrFGfNaajGYapISKv\nWGS5WnN5522UgqcYS0jOMI6xMAwTFtFXLJJcVcn0GCXsVIJljMXm3NAslnCKZRiGib5ikak1V5i9\nYjEfEbCPeXDwnmGYWqO2FEuNCUN7V1jlPjvXVFgWC7vCGIYJi8grllqOsdhhabHYPFtYo8LqpCkZ\nhokgkVcsMnausKgaMnb1sgre27mmeOY9wzC1RuQVi0rwPqqhFzvh7ckVpq86SvdjGIYJipLcIqJb\niWgTEd1JRElp/5uJ6HEiepiIvhhGBVVcYVG1WOxiQtYWi00hIfnCItpkDMPUAa6KhYjOBLBUCHEp\ngO0ArpUOPwvgYiHEJQB6iejccKppkLWRviPZaNosdoqwwmIR9opFd7qRGl4hh2GYGkHFYrkYwMbi\n9r0ALpk5IITYJ4TIFf+cRsheqQ/8btBy/8h0NPvfKZshXVZriNmN/mqy0Cwp8v+87cWEX1blMgzD\n6EAlg2QngIPF7WEAXeUnENF5ABYJIZ6xKiCdTvuu4ODxBgDh57m+cek4dk0mMJwjPD6Scj2/ISYw\nVagUzksa8ljZmMdwjnAeHcSzbc1IkEB6IoHjuRgu65zCWozjXpTyw09lp9EyuBentzajJS7w2LBx\n/2UNeXxg0Si+ebAJQ7kYhnIxdMQL+PCKcdx1uAnpyQQubJ/GkekY/nhRBun0sGu9P7gkhrsON+G6\nEzJIp4c8tFD0CfKe1SPcHpVwm5gJ0h5OaY1VFMsQgPbidgeA4/JBIloG4D8AvNVPBdxYmB8DBiZ8\nX/+HJzbh53smbY///KpudJalEL78F0cBAOd0J/F0MWf9W1c14We7jXI+eW47Nh2awv0HpkzXndgW\nx7df02va9/m11vf90v6js9upZArr1vbhyzbnvvo089/pdBp3vHaJ7TM50QfgyjN8XRppOJ+5GW6P\nSrhNzITZHiqusEcAXFncvgrA5pkDRNQG4IcAbhBCHLW4NjBBHTZxlyd0moAo+/WS5jTvWommI49h\nGMYfropFCLEFwBEi2gTgVAA/IaLbioc/BGAVgK8Q0UNEdFl4VfWH3QrDMzgdlgPqSSkmYZftkWEY\nhlFzhUEI8dGyXTcU998C4BbdldKJW955pxi2PFo4EaIuiepwaYZhGD/UwATJYBLdbfCT07L0siss\nLvnMeAFHhmEYe6KvWAJeH3dRTI4xFkmByA1VL2uWMQzDhME8UCz+y5cNE1k/8XIoDMMw9kResQTF\nzZPmZLHI+sNssejWLKypGIapH6KvWEIegOXsCpPPI8v9DMMwjJnoK5aAuBkXTnrLrFhK27pjLKyn\nGIapJyKvWMKeMeI06kwO3lOIioVhGKaeqHvFEmS0sjzcOMwYC+sphmHqicgrlnKqOeedR4UxDMN4\nJ/KKpXwd/moqFpPFImkWuxTJfuH5lgzD1BORVyxB/URBhLZ8bbjDjRmGYeqHyCuWcuPAq7EQKMbC\nrjCGYRjPRF6xiDm0DoRkLoU53JhhGKaeiL5imcN7mywW037WLAzDMHZEXrE8eHDK/SQHepviFfsa\nXRYQ6240mmVVeymrwMLGmHQ8jqUtleWe2KaUhQAA0Cytw39Su/p1DMMwUSfyEm3/WL5i360XduCL\nz41hQ3cSCxpiuCs9gVcvbsB1a5px8+NDWNaawMKGGM7sTuKKpQ146lgjXh7J4e/ObMMDBzL4X6ua\n8fDhqVkFUs4XL+7Ef++ZxHWrW7BrJIutgzmc15PCVy5ZgEePTOENKxqRKwDTBSBfEMjDSCj2J33N\nys/19VcvwB1bx9GaJPz5Ka1+m4dhGCZyUJgxjOHh4cCFz+Sfl3noml6LM+cPnLu7Em4TM9welXCb\nmNHVHh0dHRUuoMi7whiGYZjaghULwzAMoxVWLAzDMIxWWLEwDMMwWmHFwjAMw2iFFQvDMAyjFVYs\nDMMwjFZYsTAMwzBaYcXCMAzDaIUVC8MwDKMVViwMwzCMVlixMAzDMFphxcIwDMNohRULwzAMoxUl\nxUJEtxLRJiK6k4iS0v44EX2zeOwL4VWTYRiGqRVcFQsRnQlgqRDiUgDbAVwrHb4awMHisVYiujCc\najIMwzC1gorFcjGAjcXtewFconiMYRiGmYeopCbuBHCwuD0MoKvs2IjNsVnS6bTf+mFZQytemYrj\ntJYsXhhPBi6vXuA2qITbxAy3RyXcJmaCtIdT9kkVxTIEoL243QHguOIxpQq48X9XFnDfC3vx1g0n\n4un+aaxqS6C3iVMTc4pVM9wmZrg9KuE2MRNme6i4wh4BcGVx+yoAmxWPaaE9FcOGthwSMcIFvQ3o\nbYrrvgXDMAyjEVfFIoTYAuAIEW0CcCqAnxDRbcXD9wBYUTyWEUI8Gl5VGYZhmFpAxRUGIcRHy3bd\nUNyfA3C95joxDMMwNQxPkGQYhmG0woqFYRiG0QorFoZhGEYrrFgYhmEYrZAQIrTCh4eHwyucYRiG\nmXM6OjqofB9bLAzDMIxWQrVYGIZhmPkHWywMwzCMVlixMAzDMFqJvGKxSzJW7xDR+UT0KBH9DxH9\ngIiSRPRHRPQIET1ARMuK551cPOcRIrpirusdNkT0DiI6Vtzm9iC6vPj8DxLRW4nokuKzP0xEpxfP\nOUbpolUAAANOSURBVIGINhLRZiJ611zXOSyIKEZE3y7Ki4eL78K8aw8i6iCiJ4hojIhOK+5T+laI\nqIWIflpsr//tuxJCiMj+A3AmgO8Vtz8O4Lq5rlMVn30xgKbi9r8CeBuARwGkYOTB+Xrx2E8B9MFY\nZXrzXNc75DaJAfgJgGdgLEc039ujEcDdAFLSvt8BWABgBYBfFvd9AcZisQkYC8c2znXdQ2qPswH8\noLh9KYDb52N7AEgC6AHwbQCneflWANwE4P3F7XthJHn0XIeoWyzzNpGYEOKQEGKy+Oc0gLUAtgkh\npoUQm2EoXQBYIoRICyFGABwnou65qG+V+BMAPwZQALcHALwKwCSAu4noZ0S0GEBeCDEohNgHYGHx\nvPMB/FYYa/s9DUPY1COvACAiIhjKZBzzsD2EEFkhxDFpl5dvRZa5vwFwkZ86RF2xKCUSq2eIaCWA\n18FISTAiHZrJHyD/hnXbRkQUB/DHAP6ruEt+N4B51h5FFgFYA+DNAO4A8EmY2yRHRCkASSFEobiv\nntukH0AWRgr1L8OwTOZze8zg5VvRInOjrliUEonVK0TUDuBOGCtIH0OpLQAgX/y/IO2r5zZ6F4Af\nSQJBfjeA+dcegNEGm4UQ0wAeAHAWzG2SKB7LEtHMt17PbfI6ADkhxDoA1wL4LOZ3e8zg5VvRInOj\nrlhCTyQWVYgoAeCHAD4phHgJQBrAeiJKEdGrADxXPPUQEa0mojYAXUKI/jmqcticAuBPieheGH7h\nD2J+twcAPAGjDQjABgBbASSIqJOIlqMkFJ4EcHnxnToHwItzUtvwIQADxe1+GIJxPrfHDF5khyxz\nrwTwmJ8bRn6CJBF9FsCFAPYBeG+xx1H3ENG7AfwHgOeLu75W/P8mABkA7xFC7CeiUwDcBsO8/Uch\nxG+qXtkqQ0RPCSHOJaK3Y563BxH9FYC3AxAA/gzAUgCfKf79l0KIZ4uxl+8CaIERuP3uXNU3TIqK\n4i4AJwBoAPC3MALX8649iOhXMDobe2F8D5NQ+FaIqBXA9wB0A7hHCPEZX/ePumJhGIZhaouou8IY\nhmGYGoMVC8MwDKMVViwMwzCMVlixMAzDMFphxcIwDMNohRULwzAMoxVWLAzDMIxWWLEwDMMwWvn/\n8xTGpIIhDScAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8c30719128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)                # the first figure\n",
    "plt_index = 160\n",
    "for j in range(1):\n",
    "    plot_x = []\n",
    "    for i in range(len(accuracies)):\n",
    "        plot_x.append(accuracies[i][5])\n",
    "#     plt.subplot(plt_index)\n",
    "    plt.plot(plot_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with tf.Session() as sess:\n",
    "#     v = tf.constant(value=np.zeros((10, 6, 10)))\n",
    "# #     zero = tf.constant(np.arange(2))\n",
    "# #     first = tf.constant(np.arange(10))\n",
    "# #     last = tf.constant(np.arange(6))\n",
    "# #     z = v[first, zero, last]\n",
    "# #     indices = tf.constant(5)\n",
    "# # #     zero = tf.constant(0)\n",
    "# #     begin = tf.pack([indices, 0])\n",
    "# #     shape_ = tf.constant([1, 10])\n",
    "# #     zs = []\n",
    "# #     for i in range(10):\n",
    "# #         z = tf.slice(v[i, 1, :], begin=[indices, 0], size=[1, 10])\n",
    "# #         shape_z = tf.shape(z)\n",
    "# #         z = tf.reshape(z, shape=[shape_z[-1]])\n",
    "# #         zs.append(z)\n",
    "# #     tf.global_variables_initializer()\n",
    "# #     zs = tf.pack(zs, axis=0)\n",
    "#     l = tf.constant([1, 2, 3, 4, 5, 6, 7, 8, 9, 0])\n",
    "#     zs = v[0, :, l]\n",
    "#     print (sess.run(zs).shape)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
