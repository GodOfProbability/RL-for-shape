{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* colors: Number of colors\n",
    "\n",
    "* C: number of classes\n",
    "\n",
    "* A: actions {l:left, r:right, a:above, b:below}\n",
    "\n",
    "* cube: adjacency matrix of the cube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenges\n",
    "* What and when to give rewards?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things that can go wrong:\n",
    "* Stop gradient in the mean_actions\n",
    "* Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the cube adjancy matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cube = np.array([[1, 3, 4, 5], [2,0,4,5], [3,1,4,5], [0,2,4,5], [1,3,2,0], [3,1,2,0]], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* generate a dataset\n",
    "* Assume that we are generating 10 classes, with 10 colors in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "num_actions = 4\n",
    "hid_dim = 10\n",
    "gamma = 0.9\n",
    "num_colors = 3\n",
    "num_classes = batch_size\n",
    "num_faces = 6\n",
    "SMALL_NUM = 1e-10\n",
    "initLr = 0.1\n",
    "lrDecayRate = .995\n",
    "lrDecayFreq = 500\n",
    "momentumValue = .9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]], dtype=int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.random.randint(num_colors, size=(batch_size, num_faces))\n",
    "y = np.arange(num_classes)\n",
    "# converting in one-hot representation\n",
    "X_train = np.zeros((batch_size, num_faces, num_colors))\n",
    "for i in range(batch_size):\n",
    "    for j in range(num_faces):\n",
    "        X_train[i, j, X[i, j]] = 1\n",
    "\n",
    "# Make the y one-hot representation\n",
    "y_train = np.zeros((batch_size, num_classes))\n",
    "for i in range(batch_size):\n",
    "    y_train[i, y[i]] = 1\n",
    "X_train.astype(np.int32)\n",
    "y_train.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 2, 0, 0],\n",
       "       [2, 2, 1, 2, 1, 0],\n",
       "       [0, 1, 0, 1, 2, 2],\n",
       "       [1, 1, 0, 1, 2, 2],\n",
       "       [1, 0, 0, 0, 2, 2],\n",
       "       [0, 2, 1, 0, 1, 2],\n",
       "       [1, 2, 2, 0, 2, 1],\n",
       "       [1, 1, 2, 0, 0, 0],\n",
       "       [2, 0, 1, 0, 0, 1],\n",
       "       [2, 0, 0, 2, 1, 1]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Define the computation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_kernel(kernel_shape, bias_shape):\n",
    "    # Create variable named \"weights\".\n",
    "    weights = tf.get_variable(\"weights\", kernel_shape,\n",
    "        initializer=tf.random_normal_initializer())\n",
    "    # Create variable named \"biases\".\n",
    "    biases = tf.get_variable(\"biases\", bias_shape,\n",
    "                             initializer=tf.random_normal_initializer())\n",
    "    return weights, biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_next_batch(x, init_view, actions, cube):\n",
    "    \"\"\" Get the slice of the next input from the placeholder x\n",
    "    given the next location (left, right, above, below) to look at.\n",
    "    One thing to make sure that you need to first sample to face index\n",
    "    from the cube adjagit remote add origin git@github.com:GodOfProbability/RL-for-shape.gitcency matrix, given the current face and the action\n",
    "    taken.\n",
    "    : param x: complete data matrix, of shape: (batch_size, num_faces, num_colors)\n",
    "    : param init_view: the current face indices in the batch_x\n",
    "    : param actions: the action taken (l, r, a, b)\n",
    "    : param cube: the cube data adjacency matrix.\n",
    "    : return batch_x: the next_batch \n",
    "    \"\"\"\n",
    "#     init_view = tf.argmax(init_view, 1)\n",
    "    init_view = tf.cast(init_view, dtype=tf.int32)\n",
    "    size = [1, num_colors]\n",
    "    batch_x = []\n",
    "    face_indices = []\n",
    "    for i in range(batch_size):\n",
    "        # from actions, find the face index\n",
    "        face_index = cube[init_view[i, 0], actions[i, 0]]\n",
    "        face_indices.append(face_index)\n",
    "        begin = [face_index, 0]\n",
    "        z = tf.slice(x[i, :, :], begin=begin, size=size, name=\"z_slicing\")\n",
    "        z = tf.reshape(z, shape=[tf.shape(z)[-1]])\n",
    "        batch_x.append(z)\n",
    "    batch_x = tf.pack(batch_x, axis=0)\n",
    "    face_indices = tf.pack(face_indices, axis=0)\n",
    "    face_indices = tf.reshape(face_indices, shape = [tf.shape(face_indices)[0], 1])\n",
    "    return batch_x, face_indices\n",
    "\n",
    "def get_init_view(x, init_view):\n",
    "    \"\"\"Given the complete data matrix, give me the batch_x\n",
    "    :param x: complete data matrix, of shape: (batch_size, num_faces, num_colors)\n",
    "    :param init_view: the indices of the faces of the cube that \n",
    "    you see on the first time\n",
    "    :return batch_x: the batch for learning of shape (batch_size x num_colors)\n",
    "    the colors are represented in one-hot way.\n",
    "    \"\"\"\n",
    "\n",
    "    size = [1, num_colors]\n",
    "    batch_x = []\n",
    "    for i in range(batch_size):\n",
    "        begin = [init_view[i, 0], 0]\n",
    "        z = tf.slice(x[i, :, :], begin=begin, size=size)\n",
    "        z = tf.reshape(z, shape=[tf.shape(z)[-1]], name=\"z_slicing\")\n",
    "        batch_x.append(z)\n",
    "    batch_x = tf.pack(batch_x, axis=0)\n",
    "    return batch_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# x = tf.constant(X_train)\n",
    "# cubes = tf.constant(cube)\n",
    "# initial_view = tf.constant(y_train[:, 0].reshape((10, 1)))\n",
    "# actions = tf.constant([[1], [2], [3], [0], [1], [2], [3], [0], [2], [1]], dtype=tf.int32)\n",
    "# batch_x, face_indices = get_next_batch(x, initial_view, actions, cubes)\n",
    "# with tf.Session() as sess:\n",
    "#     print (sess.run(face_indices).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def model(cube):\n",
    "    x = tf.placeholder(name=\"input_data\", shape=[None, num_faces, num_colors], dtype=tf.float32) # total number of colors are 10 in one hot way\n",
    "    y = tf.placeholder(name=\"labels\", shape=[None, num_classes], dtype=tf.float32)\n",
    "    cube = tf.constant(cube)\n",
    "    REUSE = False\n",
    "    COSTS = []\n",
    "    Rewards = []\n",
    "    outputs = []\n",
    "    samp_actions = []\n",
    "    ys = []\n",
    "    accuracies = []\n",
    "    initial_views = []\n",
    "    # randomly generate first input view location.\n",
    "    init_view = tf.random_uniform((batch_size, 1), minval=0, maxval=5.99)\n",
    "    init_view = tf.to_int32(init_view, name='ToInt32')\n",
    "    hidden = tf.get_variable(\"hidden\", shape=[batch_size, hid_dim], initializer=tf.random_normal_initializer())\n",
    "    with tf.name_scope(\"init_view\") as scope:\n",
    "        batch_x = get_init_view(x, init_view)\n",
    "    for i in range(6):\n",
    "        print (i)\n",
    "        initial_views.append(init_view)\n",
    "        with tf.variable_scope(\"x_hidden\", reuse=REUSE):\n",
    "            W_x, _ = get_kernel(kernel_shape=[num_colors, hid_dim], bias_shape=[hid_dim])\n",
    "\n",
    "        with tf.variable_scope(\"hidden_hidden\", reuse=REUSE):\n",
    "            W_h, b_h = get_kernel(kernel_shape=[hid_dim, hid_dim], bias_shape=[hid_dim])\n",
    "\n",
    "        with tf.variable_scope(\"class\", reuse=REUSE):\n",
    "            W_c, b_c = get_kernel(kernel_shape=[hid_dim, num_classes], bias_shape=[num_classes])\n",
    "\n",
    "        with tf.variable_scope(\"action\", reuse=REUSE):\n",
    "            W_a, b_a = get_kernel(kernel_shape=[hid_dim, num_actions], bias_shape=[num_actions])\n",
    "\n",
    "        with tf.name_scope(\"x_to_hid\") as scope:\n",
    "            # Construct a linear model\n",
    "            x_hidden = tf.nn.relu(tf.matmul(batch_x, W_x))\n",
    "        with tf.name_scope(\"hid_to_hid\") as scope:\n",
    "            h_hid = tf.nn.relu(tf.matmul(hidden, W_h) + b_h)\n",
    "            \n",
    "        with tf.name_scope(\"hidden_t\") as scope:\n",
    "            hidden = tf.sigmoid(x_hidden + h_hid)\n",
    "\n",
    "        with tf.name_scope(\"classification\") as scope:\n",
    "            probs = tf.nn.softmax(tf.matmul(hidden, W_c) + b_c)  # Softmax prob for classes\n",
    "        \n",
    "        mean_actions = tf.nn.softmax(tf.matmul(hidden, W_a) + b_a)  # Softmax prob for actions\n",
    "        \n",
    "        # sample from these actions\n",
    "        samp_action = tf.multinomial(mean_actions, 1,)\n",
    "        samp_action = tf.cast(samp_action, dtype=tf.int32)\n",
    "        tf.stop_gradient(samp_action) # Stop the gradient flowing from non-differential cube-view sampling\n",
    "        \n",
    "        # define the rewards\n",
    "        max_p_y = tf.arg_max(probs, 1)\n",
    "        max_y = tf.arg_max(y, 1)\n",
    "\n",
    "        equals = tf.equal(max_p_y,max_y)\n",
    "        equals = tf.cast(equals, tf.float32)\n",
    "        acc = tf.reduce_mean(equals)\n",
    "        \n",
    "        R = equals\n",
    "        R = tf.reshape(R, (batch_size, 1))\n",
    "        \n",
    "        # Loss function corresponding to the policy\n",
    "        # I guess this is the probility of the action getting selected under softmax assumption\n",
    "        with tf.name_scope(\"policy_gradient\") as scope:\n",
    "#             p_loc = tf.zeros_like(samp_action, dtype=tf.float32)\n",
    "            p_loc = []\n",
    "            for index in range(batch_size):\n",
    "                p_loc.append(mean_actions[i, samp_action[i, 0]])\n",
    "            p_loc = tf.pack(p_loc, axis=0)\n",
    "            loss_p = tf.log(p_loc) * (R) * (gamma**i)\n",
    "        # Loss function correponding to the class prediction\n",
    "        with tf.name_scope(\"class_loss\") as scope:\n",
    "            # Minimize error using cross entropy, y is in one-hot representation\n",
    "            loss_class = y * tf.log(probs)\n",
    "            \n",
    "        J = tf.concat(1, [loss_p, loss_class])\n",
    "        J = tf.reduce_sum(J, 1)\n",
    "        J = tf.reduce_mean(J, 0)\n",
    "\n",
    "        cost = -J\n",
    "        COSTS.append(cost)\n",
    "#         samp_actions.append(samp_action)\n",
    "        accuracies.append(acc)\n",
    "        Rewards.append(R)\n",
    "\n",
    "        with tf.name_scope(\"get_next_batch\") as scope:\n",
    "            batch_x, init_view = get_next_batch(x, init_view, samp_action, cube)\n",
    "        \n",
    "        # Don't use the initialized variable again\n",
    "        REUSE = True\n",
    "    temp = COSTS\n",
    "    COSTS = tf.reduce_sum(COSTS)\n",
    "    reward = tf.reduce_mean(Rewards)\n",
    "#     accuracy = tf.reduce_mean(accuracies)\n",
    "    with tf.name_scope(\"train\") as scope:\n",
    "        # Gradient descent\n",
    "        optimizer = tf.train.GradientDescentOptimizer(lr).minimize(COSTS)\n",
    "    return x, y, COSTS, reward, accuracies, temp, optimizer, initial_views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "global_step = tf.Variable(0, trainable=False, dtype=tf.int32)\n",
    "lr = tf.train.exponential_decay(initLr, global_step, lrDecayFreq, lrDecayRate, staircase=True, )\n",
    "x, y, costs, reward, acc, temp, optimizer, initital_views = model(cube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    accuracies = []\n",
    "    rewards = []\n",
    "    Init_views = []\n",
    "    for i in range(1000):\n",
    "#         print (i)\n",
    "        x_, y_, costs_, reward_, acc_, temp_, _, initial_views = sess.run([x, y, costs, reward, acc, temp, optimizer, initital_views], feed_dict={x:X_train, y:y_train})\n",
    "        accuracies.append(acc_)\n",
    "        rewards.append(reward_)\n",
    "        Init_views.append(initial_views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([[4],\n",
       "         [0],\n",
       "         [1],\n",
       "         [5],\n",
       "         [0],\n",
       "         [1],\n",
       "         [0],\n",
       "         [4],\n",
       "         [5],\n",
       "         [4]], dtype=int32), array([[1],\n",
       "         [1],\n",
       "         [4],\n",
       "         [2],\n",
       "         [1],\n",
       "         [4],\n",
       "         [4],\n",
       "         [2],\n",
       "         [0],\n",
       "         [3]], dtype=int32), array([[2],\n",
       "         [2],\n",
       "         [1],\n",
       "         [4],\n",
       "         [0],\n",
       "         [2],\n",
       "         [2],\n",
       "         [4],\n",
       "         [4],\n",
       "         [4]], dtype=int32), array([[3],\n",
       "         [4],\n",
       "         [5],\n",
       "         [0],\n",
       "         [5],\n",
       "         [5],\n",
       "         [3],\n",
       "         [2],\n",
       "         [1],\n",
       "         [0]], dtype=int32), array([[4],\n",
       "         [3],\n",
       "         [2],\n",
       "         [1],\n",
       "         [3],\n",
       "         [2],\n",
       "         [2],\n",
       "         [4],\n",
       "         [5],\n",
       "         [4]], dtype=int32), array([[2],\n",
       "         [2],\n",
       "         [1],\n",
       "         [5],\n",
       "         [2],\n",
       "         [3],\n",
       "         [5],\n",
       "         [2],\n",
       "         [2],\n",
       "         [1]], dtype=int32)], [array([[1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [3],\n",
       "         [5],\n",
       "         [4],\n",
       "         [0],\n",
       "         [0],\n",
       "         [4],\n",
       "         [3]], dtype=int32), array([[2],\n",
       "         [2],\n",
       "         [5],\n",
       "         [5],\n",
       "         [3],\n",
       "         [1],\n",
       "         [3],\n",
       "         [1],\n",
       "         [2],\n",
       "         [4]], dtype=int32), array([[4],\n",
       "         [3],\n",
       "         [0],\n",
       "         [2],\n",
       "         [2],\n",
       "         [2],\n",
       "         [5],\n",
       "         [5],\n",
       "         [3],\n",
       "         [2]], dtype=int32), array([[2],\n",
       "         [2],\n",
       "         [4],\n",
       "         [3],\n",
       "         [4],\n",
       "         [5],\n",
       "         [3],\n",
       "         [3],\n",
       "         [2],\n",
       "         [1]], dtype=int32), array([[3],\n",
       "         [5],\n",
       "         [0],\n",
       "         [0],\n",
       "         [1],\n",
       "         [3],\n",
       "         [0],\n",
       "         [2],\n",
       "         [3],\n",
       "         [2]], dtype=int32), array([[0],\n",
       "         [3],\n",
       "         [5],\n",
       "         [1],\n",
       "         [4],\n",
       "         [2],\n",
       "         [1],\n",
       "         [5],\n",
       "         [0],\n",
       "         [5]], dtype=int32)])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Init_views[900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [3],\n",
       "        [5],\n",
       "        [4],\n",
       "        [0],\n",
       "        [0],\n",
       "        [4],\n",
       "        [3]], dtype=int32), array([[2],\n",
       "        [2],\n",
       "        [5],\n",
       "        [5],\n",
       "        [3],\n",
       "        [1],\n",
       "        [3],\n",
       "        [1],\n",
       "        [2],\n",
       "        [4]], dtype=int32), array([[4],\n",
       "        [3],\n",
       "        [0],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [5],\n",
       "        [5],\n",
       "        [3],\n",
       "        [2]], dtype=int32), array([[2],\n",
       "        [2],\n",
       "        [4],\n",
       "        [3],\n",
       "        [4],\n",
       "        [5],\n",
       "        [3],\n",
       "        [3],\n",
       "        [2],\n",
       "        [1]], dtype=int32), array([[3],\n",
       "        [5],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [3],\n",
       "        [0],\n",
       "        [2],\n",
       "        [3],\n",
       "        [2]], dtype=int32), array([[0],\n",
       "        [3],\n",
       "        [5],\n",
       "        [1],\n",
       "        [4],\n",
       "        [2],\n",
       "        [1],\n",
       "        [5],\n",
       "        [0],\n",
       "        [5]], dtype=int32)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Init_views[901]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.80000001, 0.80000001, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.80000001, 0.80000001, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.80000001, 0.80000001, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.80000001, 0.80000001, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.80000001, 0.80000001, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.89999998, 0.80000001, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.89999998, 0.80000001, 0.30000001, 0.2, 0.2, 0.2],\n",
       " [0.89999998, 0.70000005, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.89999998, 0.70000005, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.80000001, 0.70000005, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.80000001, 0.70000005, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.80000001, 0.70000005, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.80000001, 0.70000005, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.80000001, 0.70000005, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.80000001, 0.70000005, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.80000001, 0.70000005, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.80000001, 0.70000005, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.80000001, 0.70000005, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.80000001, 0.70000005, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.80000001, 0.70000005, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.80000001, 0.70000005, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.80000001, 0.70000005, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.80000001, 0.70000005, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.80000001, 0.70000005, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.80000001, 0.70000005, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.80000001, 0.70000005, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.80000001, 0.70000005, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.80000001, 0.70000005, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.80000001, 0.70000005, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.80000001, 0.70000005, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.80000001, 0.70000005, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.80000001, 0.70000005, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.80000001, 0.70000005, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.80000001, 0.70000005, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.80000001, 0.70000005, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.80000001, 0.70000005, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.80000001, 0.70000005, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.80000001, 0.80000001, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.80000001, 0.80000001, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.80000001, 0.80000001, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.80000001, 0.80000001, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.80000001, 0.80000001, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.80000001, 0.80000001, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.80000001, 0.80000001, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.80000001, 0.80000001, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.80000001, 0.80000001, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.80000001, 0.80000001, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.80000001, 0.80000001, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.80000001, 0.80000001, 0.2, 0.2, 0.2, 0.2],\n",
       " [0.80000001, 0.80000001, 0.2, 0.2, 0.2, 0.2]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies[900:950]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZwAAAD0CAYAAACvkZC6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbf4c40b400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)                # the first figure\n",
    "plt_index = 160\n",
    "for j in range(1):\n",
    "    plot_x = []\n",
    "    for i in range(len(accuracies)):\n",
    "        plot_x.append(accuracies[i][5])\n",
    "    plt_index = 160 + j + 1\n",
    "#     plt.subplot(plt_index)\n",
    "    plt.plot(plot_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = []\n",
    "a.append(2)\n",
    "a.append(3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# with tf.Session() as sess:\n",
    "#     v = tf.constant(value=np.zeros((10, 6, 10)))\n",
    "# #     zero = tf.constant(np.arange(2))\n",
    "# #     first = tf.constant(np.arange(10))\n",
    "# #     last = tf.constant(np.arange(6))\n",
    "# #     z = v[first, zero, last]\n",
    "# #     indices = tf.constant(5)\n",
    "# # #     zero = tf.constant(0)\n",
    "# #     begin = tf.pack([indices, 0])\n",
    "# #     shape_ = tf.constant([1, 10])\n",
    "# #     zs = []\n",
    "# #     for i in range(10):\n",
    "# #         z = tf.slice(v[i, 1, :], begin=[indices, 0], size=[1, 10])\n",
    "# #         shape_z = tf.shape(z)\n",
    "# #         z = tf.reshape(z, shape=[shape_z[-1]])\n",
    "# #         zs.append(z)\n",
    "# #     tf.global_variables_initializer()\n",
    "# #     zs = tf.pack(zs, axis=0)\n",
    "#     l = tf.constant([1, 2, 3, 4, 5, 6, 7, 8, 9, 0])\n",
    "#     zs = v[0, :, l]\n",
    "#     print (sess.run(zs).shape)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
